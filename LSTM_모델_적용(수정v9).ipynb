{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayz1070/CapstoneStockModelingProject/blob/main/LSTM_%EB%AA%A8%EB%8D%B8_%EC%A0%81%EC%9A%A9(%EC%88%98%EC%A0%95v9).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install finance-datareader\n",
        "!pip install pykrx\n",
        "!pip install pyOpenSSL"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5X1fD2CfXH-R",
        "outputId": "1484ede8-2aac-423c-ab48-45b15003910b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting finance-datareader\n",
            "  Downloading finance_datareader-0.9.50-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: pandas>=0.19.2 in /usr/local/lib/python3.10/dist-packages (from finance-datareader) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from finance-datareader) (2.31.0)\n",
            "Collecting requests-file (from finance-datareader)\n",
            "  Downloading requests_file-1.5.1-py2.py3-none-any.whl (3.7 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from finance-datareader) (4.9.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from finance-datareader) (4.66.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.19.2->finance-datareader) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.19.2->finance-datareader) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.19.2->finance-datareader) (1.23.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.3.0->finance-datareader) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.3.0->finance-datareader) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.3.0->finance-datareader) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.3.0->finance-datareader) (2023.7.22)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from requests-file->finance-datareader) (1.16.0)\n",
            "Installing collected packages: requests-file, finance-datareader\n",
            "Successfully installed finance-datareader-0.9.50 requests-file-1.5.1\n",
            "Collecting pykrx\n",
            "  Downloading pykrx-1.0.45-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pykrx) (2.31.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from pykrx) (1.5.3)\n",
            "Collecting datetime (from pykrx)\n",
            "  Downloading DateTime-5.2-py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.2/52.2 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pykrx) (1.23.5)\n",
            "Requirement already satisfied: xlrd in /usr/local/lib/python3.10/dist-packages (from pykrx) (2.0.1)\n",
            "Collecting deprecated (from pykrx)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: multipledispatch in /usr/local/lib/python3.10/dist-packages (from pykrx) (1.0.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from pykrx) (3.7.1)\n",
            "Collecting zope.interface (from datetime->pykrx)\n",
            "  Downloading zope.interface-6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (246 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.0/247.0 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from datetime->pykrx) (2023.3.post1)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated->pykrx) (1.15.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pykrx) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pykrx) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pykrx) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pykrx) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pykrx) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pykrx) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pykrx) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pykrx) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pykrx) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pykrx) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pykrx) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pykrx) (2023.7.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->pykrx) (1.16.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from zope.interface->datetime->pykrx) (67.7.2)\n",
            "Installing collected packages: zope.interface, deprecated, datetime, pykrx\n",
            "Successfully installed datetime-5.2 deprecated-1.2.14 pykrx-1.0.45 zope.interface-6.0\n",
            "Requirement already satisfied: pyOpenSSL in /usr/local/lib/python3.10/dist-packages (23.2.0)\n",
            "Requirement already satisfied: cryptography!=40.0.0,!=40.0.1,<42,>=38.0.0 in /usr/local/lib/python3.10/dist-packages (from pyOpenSSL) (41.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography!=40.0.0,!=40.0.1,<42,>=38.0.0->pyOpenSSL) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography!=40.0.0,!=40.0.1,<42,>=38.0.0->pyOpenSSL) (2.21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NpF3gfFjhR0A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "outputId": "69e6d369-caab-441f-f291-6953859c8a1a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-df5e4c4f-b3c7-4909-be88-b4771de1b239\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-df5e4c4f-b3c7-4909-be88-b4771de1b239\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kospi100.xlsx to kospi100.xlsx\n"
          ]
        }
      ],
      "source": [
        "import FinanceDataReader as fdr\n",
        "import yfinance as yf\n",
        "import openpyxl\n",
        "from pykrx import stock\n",
        "import time\n",
        "import datetime\n",
        "import ssl\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from time import sleep\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Conv1D, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.losses import Huber\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Colab => 데이터 CSV파일 가져오기\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "kospi = pd.read_excel(\"kospi100.xlsx\", engine='openpyxl')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 오늘의 날짜를 \"today2\"에 저장\n",
        "today=datetime.datetime.today().strftime(\"%Y-%m-%d\")\n",
        "today2=datetime.datetime.today().strftime(\"%Y%m%d\")\n",
        "\n",
        "# :n --> kospi100,xlsx 파일의 종목중 위에서부터 n개 종목명 가져옴\n",
        "companies = kospi['Name'][:2].tolist()\n",
        "\n",
        "stocks = fdr.StockListing('KOSPI') # 코스피\n",
        "stocks=stocks[['Code','Name']]\n",
        "\n",
        "# 주가 정보\n",
        "merged_df = pd.merge(kospi, stocks, on='Name', how='left')\n",
        "merged_df[merged_df['Code'].isnull()]\n",
        "merged_df=merged_df.dropna(axis=0)\n",
        "\n",
        "# 환율 데이터\n",
        "start_date = '2015-01-01'\n",
        "data = yf.download(['USDKRW=X'],start=start_date, end=today)\n",
        "data=data[['Close']]\n",
        "data =data.rename(columns={'Close':'환율'})\n",
        "\n",
        "# 금리 데이터\n",
        "apikey='EPJ2CONXWQOE8KWK59GV'\n",
        "def EcosDownload(Statcode, Freq, Begdate, Enddate, Subcode1, Subcode2, Subcode3):\n",
        "    url = 'http://ecos.bok.or.kr/api/StatisticSearch/%s/xml/kr/1/100000/%s/%s/%s/%s/%s/%s/%s/'%(apikey, Statcode, Freq, Begdate, Enddate, Subcode1, Subcode2, Subcode3)\n",
        "    raw = requests.get(url)\n",
        "    xml = BeautifulSoup(raw.text,'xml')\n",
        "\n",
        "    # Pandas 데이터프레임으로 전환합니다.\n",
        "    raw_data = xml.find_all(\"row\")\n",
        "    date_list = []\n",
        "    value_list = []\n",
        "\n",
        "    for item in raw_data:\n",
        "        value = item.find('DATA_VALUE').text.encode('utf-8')\n",
        "        date_str = item.find('TIME').text\n",
        "        value = float(value)\n",
        "        date_list.append(datetime.datetime.strptime(date_str,'%Y%m%d'))\n",
        "        value_list.append(value)\n",
        "\n",
        "    df = pd.DataFrame(index = date_list)\n",
        "    df['금리'] = value_list\n",
        "    return df\n",
        "df1 = EcosDownload('722Y001', 'D', '20150101', today2, '0101000','','')\n",
        "df1.index = df1.index.rename('Date')"
      ],
      "metadata": {
        "id": "cNBzmZe1g77k",
        "outputId": "e8d120c2-9291-45ba-9a74-95ea2e9c750c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[*********************100%%**********************]  1 of 1 completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sequence_dataset 만들기\n",
        "def make_sequence_dataset(feature, label, window_size):\n",
        "  feature_list = []   # 생성될 feature list\n",
        "  label_list = []     # 생성될 label list\n",
        "\n",
        "  for i in range(len(feature)-window_size): # range는 전체값에서 window_size를 뺀 값\n",
        "    feature_list.append(feature[i:i+window_size]) # feature list 에 i번째서 부터 window size 만큼의 입력데이터를 추가\n",
        "    label_list.append(label[i+window_size]) # label list 에 그 다음 번째('window_size + 1' 번째)의 정답데이터를 추가\n",
        "  return np.array(feature_list), np.array(label_list)\n",
        "\n",
        "# 예측값 저장 dict 만들기\n",
        "day_five = {}\n",
        "day_ten = {}"
      ],
      "metadata": {
        "id": "2-i7vtCNieta"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "f2bf7bb2",
        "outputId": "f805e5e4-a5ef-432d-b381-16145b917fef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "46/46 [==============================] - 4s 28ms/step - loss: 0.1629 - mse: 0.3290\n",
            "Epoch 2/100\n",
            "46/46 [==============================] - 2s 35ms/step - loss: 0.0491 - mse: 0.0983\n",
            "Epoch 3/100\n",
            "46/46 [==============================] - 2s 45ms/step - loss: 0.0225 - mse: 0.0450\n",
            "Epoch 4/100\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 0.0175 - mse: 0.0349\n",
            "Epoch 5/100\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 0.0145 - mse: 0.0291\n",
            "Epoch 6/100\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 0.0114 - mse: 0.0228\n",
            "Epoch 7/100\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 0.0074 - mse: 0.0147\n",
            "Epoch 8/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 0.0041 - mse: 0.0083\n",
            "Epoch 9/100\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 0.0030 - mse: 0.0060\n",
            "Epoch 10/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 0.0021 - mse: 0.0042\n",
            "Epoch 11/100\n",
            "46/46 [==============================] - 1s 31ms/step - loss: 0.0015 - mse: 0.0031\n",
            "Epoch 12/100\n",
            "46/46 [==============================] - 2s 46ms/step - loss: 0.0012 - mse: 0.0024\n",
            "Epoch 13/100\n",
            "46/46 [==============================] - 2s 48ms/step - loss: 0.0010 - mse: 0.0020\n",
            "Epoch 14/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 8.6099e-04 - mse: 0.0017\n",
            "Epoch 15/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 7.7673e-04 - mse: 0.0016\n",
            "Epoch 16/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 6.7680e-04 - mse: 0.0014\n",
            "Epoch 17/100\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 5.9992e-04 - mse: 0.0012\n",
            "Epoch 18/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 5.5450e-04 - mse: 0.0011\n",
            "Epoch 19/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 4.9802e-04 - mse: 9.9604e-04\n",
            "Epoch 20/100\n",
            "46/46 [==============================] - 2s 46ms/step - loss: 4.6067e-04 - mse: 9.2134e-04\n",
            "Epoch 21/100\n",
            "46/46 [==============================] - 3s 57ms/step - loss: 4.6838e-04 - mse: 9.3676e-04\n",
            "Epoch 22/100\n",
            "46/46 [==============================] - 3s 53ms/step - loss: 4.0481e-04 - mse: 8.0962e-04\n",
            "Epoch 23/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 3.8030e-04 - mse: 7.6060e-04\n",
            "Epoch 24/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 3.6768e-04 - mse: 7.3537e-04\n",
            "Epoch 25/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 3.4970e-04 - mse: 6.9940e-04\n",
            "Epoch 26/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 3.4747e-04 - mse: 6.9493e-04\n",
            "Epoch 27/100\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 3.1989e-04 - mse: 6.3978e-04\n",
            "Epoch 28/100\n",
            "46/46 [==============================] - 2s 38ms/step - loss: 3.1159e-04 - mse: 6.2318e-04\n",
            "Epoch 29/100\n",
            "46/46 [==============================] - 2s 41ms/step - loss: 2.9971e-04 - mse: 5.9942e-04\n",
            "Epoch 30/100\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 3.1334e-04 - mse: 6.2668e-04\n",
            "Epoch 31/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 2.9305e-04 - mse: 5.8610e-04\n",
            "Epoch 32/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 2.8964e-04 - mse: 5.7927e-04\n",
            "Epoch 33/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 2.8449e-04 - mse: 5.6897e-04\n",
            "Epoch 34/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 2.7634e-04 - mse: 5.5268e-04\n",
            "Epoch 35/100\n",
            "46/46 [==============================] - 1s 29ms/step - loss: 2.6801e-04 - mse: 5.3601e-04\n",
            "Epoch 36/100\n",
            "46/46 [==============================] - 2s 37ms/step - loss: 2.7428e-04 - mse: 5.4857e-04\n",
            "Epoch 37/100\n",
            "46/46 [==============================] - 2s 43ms/step - loss: 2.6846e-04 - mse: 5.3693e-04\n",
            "Epoch 38/100\n",
            "46/46 [==============================] - 2s 38ms/step - loss: 2.6130e-04 - mse: 5.2261e-04\n",
            "Epoch 39/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 2.6900e-04 - mse: 5.3800e-04\n",
            "Epoch 40/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 2.6001e-04 - mse: 5.2002e-04\n",
            "Epoch 41/100\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 2.7246e-04 - mse: 5.4493e-04\n",
            "Epoch 42/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 2.5273e-04 - mse: 5.0547e-04\n",
            "Epoch 43/100\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 2.4805e-04 - mse: 4.9610e-04\n",
            "Epoch 44/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 2.3729e-04 - mse: 4.7459e-04\n",
            "Epoch 45/100\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 2.3731e-04 - mse: 4.7463e-04\n",
            "Epoch 46/100\n",
            "46/46 [==============================] - 2s 37ms/step - loss: 2.4027e-04 - mse: 4.8055e-04\n",
            "Epoch 47/100\n",
            "46/46 [==============================] - 2s 43ms/step - loss: 2.3633e-04 - mse: 4.7267e-04\n",
            "Epoch 48/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 2.3607e-04 - mse: 4.7214e-04\n",
            "Epoch 49/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 2.3462e-04 - mse: 4.6924e-04\n",
            "Epoch 50/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 2.2523e-04 - mse: 4.5046e-04\n",
            "Epoch 51/100\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 2.3510e-04 - mse: 4.7019e-04\n",
            "Epoch 52/100\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 2.2786e-04 - mse: 4.5572e-04\n",
            "Epoch 53/100\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 2.3412e-04 - mse: 4.6823e-04\n",
            "Epoch 54/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 2.2146e-04 - mse: 4.4292e-04\n",
            "Epoch 55/100\n",
            "46/46 [==============================] - 1s 32ms/step - loss: 2.3770e-04 - mse: 4.7540e-04\n",
            "Epoch 56/100\n",
            "46/46 [==============================] - 2s 45ms/step - loss: 2.2252e-04 - mse: 4.4505e-04\n",
            "Epoch 57/100\n",
            "46/46 [==============================] - 1s 30ms/step - loss: 2.1541e-04 - mse: 4.3082e-04\n",
            "Epoch 58/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 2.1883e-04 - mse: 4.3766e-04\n",
            "Epoch 59/100\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 2.2222e-04 - mse: 4.4445e-04\n",
            "Epoch 60/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 2.0746e-04 - mse: 4.1492e-04\n",
            "Epoch 61/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 2.0301e-04 - mse: 4.0601e-04\n",
            "Epoch 62/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 2.0321e-04 - mse: 4.0642e-04\n",
            "Epoch 63/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 2.2333e-04 - mse: 4.4667e-04\n",
            "Epoch 64/100\n",
            "46/46 [==============================] - 1s 29ms/step - loss: 2.0069e-04 - mse: 4.0138e-04\n",
            "Epoch 65/100\n",
            "46/46 [==============================] - 2s 44ms/step - loss: 2.0403e-04 - mse: 4.0807e-04\n",
            "Epoch 66/100\n",
            "46/46 [==============================] - 2s 35ms/step - loss: 1.9969e-04 - mse: 3.9938e-04\n",
            "Epoch 67/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 2.0468e-04 - mse: 4.0937e-04\n",
            "Epoch 68/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 2.1795e-04 - mse: 4.3591e-04\n",
            "Epoch 69/100\n",
            "46/46 [==============================] - 2s 36ms/step - loss: 1.9920e-04 - mse: 3.9839e-04\n",
            "Epoch 70/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 1.9751e-04 - mse: 3.9502e-04\n",
            "Epoch 71/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 1.9991e-04 - mse: 3.9983e-04\n",
            "Epoch 72/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 2.0601e-04 - mse: 4.1203e-04\n",
            "Epoch 73/100\n",
            "46/46 [==============================] - 1s 29ms/step - loss: 1.8882e-04 - mse: 3.7765e-04\n",
            "Epoch 74/100\n",
            "46/46 [==============================] - 2s 46ms/step - loss: 1.8716e-04 - mse: 3.7431e-04\n",
            "Epoch 75/100\n",
            "46/46 [==============================] - 2s 33ms/step - loss: 1.8723e-04 - mse: 3.7445e-04\n",
            "Epoch 76/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 1.8873e-04 - mse: 3.7747e-04\n",
            "Epoch 77/100\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 1.9446e-04 - mse: 3.8892e-04\n",
            "Epoch 78/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 1.8619e-04 - mse: 3.7239e-04\n",
            "Epoch 79/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 1.7786e-04 - mse: 3.5572e-04\n",
            "Epoch 80/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 1.9051e-04 - mse: 3.8103e-04\n",
            "Epoch 81/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 1.7705e-04 - mse: 3.5409e-04\n",
            "Epoch 82/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 1.8135e-04 - mse: 3.6270e-04\n",
            "Epoch 83/100\n",
            "46/46 [==============================] - 2s 42ms/step - loss: 1.7790e-04 - mse: 3.5580e-04\n",
            "Epoch 84/100\n",
            "46/46 [==============================] - 2s 37ms/step - loss: 1.7497e-04 - mse: 3.4995e-04\n",
            "Epoch 85/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 1.7291e-04 - mse: 3.4582e-04\n",
            "Epoch 86/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 1.7059e-04 - mse: 3.4118e-04\n",
            "Epoch 87/100\n",
            "46/46 [==============================] - 2s 44ms/step - loss: 1.6929e-04 - mse: 3.3858e-04\n",
            "Epoch 88/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 1.8105e-04 - mse: 3.6209e-04\n",
            "Epoch 89/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 1.8778e-04 - mse: 3.7556e-04\n",
            "Epoch 90/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 2.3172e-04 - mse: 4.6343e-04\n",
            "Epoch 91/100\n",
            "46/46 [==============================] - 1s 31ms/step - loss: 1.7016e-04 - mse: 3.4033e-04\n",
            "Epoch 92/100\n",
            "46/46 [==============================] - 2s 45ms/step - loss: 1.7155e-04 - mse: 3.4310e-04\n",
            "Epoch 93/100\n",
            "46/46 [==============================] - 1s 31ms/step - loss: 1.6421e-04 - mse: 3.2843e-04\n",
            "Epoch 94/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 1.6891e-04 - mse: 3.3782e-04\n",
            "Epoch 95/100\n",
            "46/46 [==============================] - 2s 36ms/step - loss: 1.6366e-04 - mse: 3.2732e-04\n",
            "Epoch 96/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 1.6259e-04 - mse: 3.2517e-04\n",
            "Epoch 97/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 1.8706e-04 - mse: 3.7412e-04\n",
            "Epoch 98/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 1.6414e-04 - mse: 3.2828e-04\n",
            "Epoch 99/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 1.6317e-04 - mse: 3.2633e-04\n",
            "Epoch 100/100\n",
            "46/46 [==============================] - 1s 33ms/step - loss: 1.5372e-04 - mse: 3.0745e-04\n",
            "20/20 [==============================] - 1s 7ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Epoch 1/100\n",
            "46/46 [==============================] - 5s 29ms/step - loss: 0.1026 - mse: 0.2055\n",
            "Epoch 2/100\n",
            "46/46 [==============================] - 1s 29ms/step - loss: 0.0332 - mse: 0.0664\n",
            "Epoch 3/100\n",
            "46/46 [==============================] - 2s 37ms/step - loss: 0.0175 - mse: 0.0349\n",
            "Epoch 4/100\n",
            "46/46 [==============================] - 2s 39ms/step - loss: 0.0129 - mse: 0.0258\n",
            "Epoch 5/100\n",
            "46/46 [==============================] - 2s 32ms/step - loss: 0.0098 - mse: 0.0195\n",
            "Epoch 6/100\n",
            "46/46 [==============================] - 2s 41ms/step - loss: 0.0072 - mse: 0.0143\n",
            "Epoch 7/100\n",
            "46/46 [==============================] - 2s 40ms/step - loss: 0.0056 - mse: 0.0112\n",
            "Epoch 8/100\n",
            "46/46 [==============================] - 2s 43ms/step - loss: 0.0046 - mse: 0.0092\n",
            "Epoch 9/100\n",
            "46/46 [==============================] - 1s 29ms/step - loss: 0.0038 - mse: 0.0076\n",
            "Epoch 10/100\n",
            "46/46 [==============================] - 1s 29ms/step - loss: 0.0032 - mse: 0.0065\n",
            "Epoch 11/100\n",
            "46/46 [==============================] - 2s 36ms/step - loss: 0.0028 - mse: 0.0056\n",
            "Epoch 12/100\n",
            "46/46 [==============================] - 1s 29ms/step - loss: 0.0023 - mse: 0.0047\n",
            "Epoch 13/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 0.0020 - mse: 0.0040\n",
            "Epoch 14/100\n",
            "46/46 [==============================] - 1s 29ms/step - loss: 0.0017 - mse: 0.0033\n",
            "Epoch 15/100\n",
            "46/46 [==============================] - 2s 38ms/step - loss: 0.0014 - mse: 0.0028\n",
            "Epoch 16/100\n",
            "46/46 [==============================] - 2s 46ms/step - loss: 0.0012 - mse: 0.0023\n",
            "Epoch 17/100\n",
            "46/46 [==============================] - 1s 32ms/step - loss: 9.9465e-04 - mse: 0.0020\n",
            "Epoch 18/100\n",
            "46/46 [==============================] - 1s 29ms/step - loss: 8.1810e-04 - mse: 0.0016\n",
            "Epoch 19/100\n",
            "46/46 [==============================] - 1s 29ms/step - loss: 7.2055e-04 - mse: 0.0014\n",
            "Epoch 20/100\n",
            "46/46 [==============================] - 1s 29ms/step - loss: 6.3682e-04 - mse: 0.0013\n",
            "Epoch 21/100\n",
            "46/46 [==============================] - 1s 29ms/step - loss: 5.7300e-04 - mse: 0.0011\n",
            "Epoch 22/100\n",
            "46/46 [==============================] - 1s 29ms/step - loss: 5.1924e-04 - mse: 0.0010\n",
            "Epoch 23/100\n",
            "46/46 [==============================] - 1s 29ms/step - loss: 4.6112e-04 - mse: 9.2224e-04\n",
            "Epoch 24/100\n",
            "46/46 [==============================] - 2s 42ms/step - loss: 4.5757e-04 - mse: 9.1514e-04\n",
            "Epoch 25/100\n",
            "46/46 [==============================] - 2s 44ms/step - loss: 4.0793e-04 - mse: 8.1586e-04\n",
            "Epoch 26/100\n",
            "46/46 [==============================] - 1s 29ms/step - loss: 3.8078e-04 - mse: 7.6155e-04\n",
            "Epoch 27/100\n",
            "46/46 [==============================] - 2s 35ms/step - loss: 3.5837e-04 - mse: 7.1674e-04\n",
            "Epoch 28/100\n",
            "46/46 [==============================] - 1s 29ms/step - loss: 3.4929e-04 - mse: 6.9859e-04\n",
            "Epoch 29/100\n",
            "46/46 [==============================] - 2s 36ms/step - loss: 3.5612e-04 - mse: 7.1224e-04\n",
            "Epoch 30/100\n",
            "46/46 [==============================] - 1s 30ms/step - loss: 3.2034e-04 - mse: 6.4069e-04\n",
            "Epoch 31/100\n",
            "46/46 [==============================] - 1s 29ms/step - loss: 3.1197e-04 - mse: 6.2394e-04\n",
            "Epoch 32/100\n",
            "46/46 [==============================] - 1s 29ms/step - loss: 3.0962e-04 - mse: 6.1924e-04\n",
            "Epoch 33/100\n",
            "46/46 [==============================] - 2s 45ms/step - loss: 2.9651e-04 - mse: 5.9302e-04\n",
            "Epoch 34/100\n",
            "46/46 [==============================] - 2s 37ms/step - loss: 2.9483e-04 - mse: 5.8966e-04\n",
            "Epoch 35/100\n",
            "46/46 [==============================] - 1s 29ms/step - loss: 2.8317e-04 - mse: 5.6634e-04\n",
            "Epoch 36/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 2.8671e-04 - mse: 5.7341e-04\n",
            "Epoch 37/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 2.7793e-04 - mse: 5.5586e-04\n",
            "Epoch 38/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 2.8862e-04 - mse: 5.7724e-04\n",
            "Epoch 39/100\n",
            "46/46 [==============================] - 1s 29ms/step - loss: 2.7395e-04 - mse: 5.4790e-04\n",
            "Epoch 40/100\n",
            "46/46 [==============================] - 2s 48ms/step - loss: 2.7354e-04 - mse: 5.4708e-04\n",
            "Epoch 41/100\n",
            "46/46 [==============================] - 3s 68ms/step - loss: 2.5962e-04 - mse: 5.1925e-04\n",
            "Epoch 42/100\n",
            "46/46 [==============================] - 3s 74ms/step - loss: 2.6095e-04 - mse: 5.2190e-04\n",
            "Epoch 43/100\n",
            "46/46 [==============================] - 3s 69ms/step - loss: 2.5942e-04 - mse: 5.1883e-04\n",
            "Epoch 44/100\n",
            "46/46 [==============================] - 3s 67ms/step - loss: 2.4992e-04 - mse: 4.9984e-04\n",
            "Epoch 45/100\n",
            "46/46 [==============================] - 3s 66ms/step - loss: 2.4908e-04 - mse: 4.9816e-04\n",
            "Epoch 46/100\n",
            "46/46 [==============================] - 3s 56ms/step - loss: 2.7043e-04 - mse: 5.4086e-04\n",
            "Epoch 47/100\n",
            "46/46 [==============================] - 1s 30ms/step - loss: 2.5890e-04 - mse: 5.1780e-04\n",
            "Epoch 48/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 2.4777e-04 - mse: 4.9555e-04\n",
            "Epoch 49/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 2.4605e-04 - mse: 4.9210e-04\n",
            "Epoch 50/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 2.3631e-04 - mse: 4.7262e-04\n",
            "Epoch 51/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 2.3115e-04 - mse: 4.6230e-04\n",
            "Epoch 52/100\n",
            "46/46 [==============================] - 1s 29ms/step - loss: 2.2968e-04 - mse: 4.5936e-04\n",
            "Epoch 53/100\n",
            "46/46 [==============================] - 1s 31ms/step - loss: 2.2821e-04 - mse: 4.5642e-04\n",
            "Epoch 54/100\n",
            "46/46 [==============================] - 2s 45ms/step - loss: 2.2279e-04 - mse: 4.4559e-04\n",
            "Epoch 55/100\n",
            "46/46 [==============================] - 2s 33ms/step - loss: 2.2905e-04 - mse: 4.5810e-04\n",
            "Epoch 56/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 2.2201e-04 - mse: 4.4401e-04\n",
            "Epoch 57/100\n",
            "46/46 [==============================] - 1s 29ms/step - loss: 2.2187e-04 - mse: 4.4375e-04\n",
            "Epoch 58/100\n",
            "46/46 [==============================] - 1s 29ms/step - loss: 2.4229e-04 - mse: 4.8458e-04\n",
            "Epoch 59/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 2.1590e-04 - mse: 4.3179e-04\n",
            "Epoch 60/100\n",
            "46/46 [==============================] - 1s 29ms/step - loss: 2.1185e-04 - mse: 4.2370e-04\n",
            "Epoch 61/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 2.1505e-04 - mse: 4.3010e-04\n",
            "Epoch 62/100\n",
            "46/46 [==============================] - 1s 31ms/step - loss: 2.0887e-04 - mse: 4.1775e-04\n",
            "Epoch 63/100\n",
            "46/46 [==============================] - 2s 45ms/step - loss: 2.1255e-04 - mse: 4.2510e-04\n",
            "Epoch 64/100\n",
            "46/46 [==============================] - 2s 32ms/step - loss: 2.0665e-04 - mse: 4.1330e-04\n",
            "Epoch 65/100\n",
            "46/46 [==============================] - 1s 29ms/step - loss: 2.3278e-04 - mse: 4.6555e-04\n",
            "Epoch 66/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 2.1783e-04 - mse: 4.3566e-04\n",
            "Epoch 67/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 2.0278e-04 - mse: 4.0555e-04\n",
            "Epoch 68/100\n",
            "46/46 [==============================] - 1s 29ms/step - loss: 1.9884e-04 - mse: 3.9767e-04\n",
            "Epoch 69/100\n",
            "46/46 [==============================] - 1s 29ms/step - loss: 2.0407e-04 - mse: 4.0814e-04\n",
            "Epoch 70/100\n",
            "46/46 [==============================] - 1s 29ms/step - loss: 2.0101e-04 - mse: 4.0202e-04\n",
            "Epoch 71/100\n",
            "46/46 [==============================] - 1s 32ms/step - loss: 1.9621e-04 - mse: 3.9242e-04\n",
            "Epoch 72/100\n",
            "46/46 [==============================] - 2s 46ms/step - loss: 1.9089e-04 - mse: 3.8177e-04\n",
            "Epoch 73/100\n",
            "46/46 [==============================] - 1s 32ms/step - loss: 1.9504e-04 - mse: 3.9007e-04\n",
            "Epoch 74/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 1.9249e-04 - mse: 3.8497e-04\n",
            "Epoch 75/100\n",
            "46/46 [==============================] - 1s 29ms/step - loss: 1.9452e-04 - mse: 3.8905e-04\n",
            "Epoch 76/100\n",
            "46/46 [==============================] - 1s 29ms/step - loss: 1.8920e-04 - mse: 3.7841e-04\n",
            "Epoch 77/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 1.8960e-04 - mse: 3.7920e-04\n",
            "Epoch 78/100\n",
            "46/46 [==============================] - 1s 29ms/step - loss: 1.9466e-04 - mse: 3.8932e-04\n",
            "Epoch 79/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 1.9446e-04 - mse: 3.8893e-04\n",
            "Epoch 80/100\n",
            "46/46 [==============================] - 1s 31ms/step - loss: 1.8149e-04 - mse: 3.6298e-04\n",
            "Epoch 81/100\n",
            "46/46 [==============================] - 2s 44ms/step - loss: 1.8311e-04 - mse: 3.6623e-04\n",
            "Epoch 82/100\n",
            "46/46 [==============================] - 2s 34ms/step - loss: 2.0287e-04 - mse: 4.0574e-04\n",
            "Epoch 83/100\n",
            "46/46 [==============================] - 1s 29ms/step - loss: 1.7753e-04 - mse: 3.5506e-04\n",
            "Epoch 84/100\n",
            "46/46 [==============================] - 1s 29ms/step - loss: 1.7718e-04 - mse: 3.5437e-04\n",
            "Epoch 85/100\n",
            "46/46 [==============================] - 1s 29ms/step - loss: 1.7548e-04 - mse: 3.5096e-04\n",
            "Epoch 86/100\n",
            "46/46 [==============================] - 1s 29ms/step - loss: 1.7576e-04 - mse: 3.5152e-04\n",
            "Epoch 87/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 1.7940e-04 - mse: 3.5879e-04\n",
            "Epoch 88/100\n",
            "46/46 [==============================] - 1s 29ms/step - loss: 1.6971e-04 - mse: 3.3942e-04\n",
            "Epoch 89/100\n",
            "46/46 [==============================] - 1s 31ms/step - loss: 1.7948e-04 - mse: 3.5896e-04\n",
            "Epoch 90/100\n",
            "46/46 [==============================] - 2s 47ms/step - loss: 1.8176e-04 - mse: 3.6351e-04\n",
            "Epoch 91/100\n",
            "46/46 [==============================] - 2s 33ms/step - loss: 1.7273e-04 - mse: 3.4545e-04\n",
            "Epoch 92/100\n",
            "46/46 [==============================] - 1s 29ms/step - loss: 1.6725e-04 - mse: 3.3449e-04\n",
            "Epoch 93/100\n",
            "46/46 [==============================] - 1s 29ms/step - loss: 1.7029e-04 - mse: 3.4058e-04\n",
            "Epoch 94/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 1.6672e-04 - mse: 3.3343e-04\n",
            "Epoch 95/100\n",
            "46/46 [==============================] - 1s 29ms/step - loss: 1.7169e-04 - mse: 3.4338e-04\n",
            "Epoch 96/100\n",
            "46/46 [==============================] - 1s 29ms/step - loss: 1.6711e-04 - mse: 3.3423e-04\n",
            "Epoch 97/100\n",
            "46/46 [==============================] - 1s 29ms/step - loss: 1.6116e-04 - mse: 3.2232e-04\n",
            "Epoch 98/100\n",
            "46/46 [==============================] - 2s 33ms/step - loss: 1.5638e-04 - mse: 3.1275e-04\n",
            "Epoch 99/100\n",
            "46/46 [==============================] - 2s 45ms/step - loss: 1.5713e-04 - mse: 3.1426e-04\n",
            "Epoch 100/100\n",
            "46/46 [==============================] - 2s 32ms/step - loss: 1.5749e-04 - mse: 3.1498e-04\n",
            "20/20 [==============================] - 1s 7ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "5일 예측값 [[63507.38  62880.85  61536.746 62177.938 63237.645]]\n",
            "10일 예측값 [[64283.68  62747.516 65553.32  65396.4   67215.48  66289.41  62844.285\n",
            "  67169.695 65918.07  64909.54 ]]\n",
            "/n\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-2ada8c5aefa5>:177: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  close_5df['Date'] = pd.to_datetime(close_5df['Date'])  # Date 열을 날짜로 변환\n",
            "<ipython-input-5-2ada8c5aefa5>:182: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  close_10df['Date'] = pd.to_datetime(close_10df['Date'])  # Date 열을 날짜로 변환\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "8/8 [==============================] - 3s 47ms/step - loss: 0.1465 - mse: 0.2937\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 0.1192 - mse: 0.2385\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.0969 - mse: 0.1939\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 0s 48ms/step - loss: 0.0798 - mse: 0.1597\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.0656 - mse: 0.1312\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0537 - mse: 0.1073\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0441 - mse: 0.0881\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.0374 - mse: 0.0747\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.0326 - mse: 0.0652\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.0298 - mse: 0.0595\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.0280 - mse: 0.0560\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.0267 - mse: 0.0534\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0252 - mse: 0.0504\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0236 - mse: 0.0472\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0219 - mse: 0.0438\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0200 - mse: 0.0399\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0179 - mse: 0.0358\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.0161 - mse: 0.0322\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.0146 - mse: 0.0292\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.0135 - mse: 0.0271\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0128 - mse: 0.0257\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.0124 - mse: 0.0249\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.0120 - mse: 0.0239\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.0115 - mse: 0.0229\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.0109 - mse: 0.0217\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0106 - mse: 0.0211\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.0102 - mse: 0.0203\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.0099 - mse: 0.0197\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.0096 - mse: 0.0191\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0093 - mse: 0.0186\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.0090 - mse: 0.0180\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.0089 - mse: 0.0177\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.0085 - mse: 0.0170\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0081 - mse: 0.0162\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0078 - mse: 0.0157\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.0075 - mse: 0.0150\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.0072 - mse: 0.0145\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.0071 - mse: 0.0141\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0067 - mse: 0.0134\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.0065 - mse: 0.0130\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.0067 - mse: 0.0133\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.0064 - mse: 0.0127\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0061 - mse: 0.0121\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0057 - mse: 0.0114\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 0.0052 - mse: 0.0104\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.0053 - mse: 0.0105\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.0050 - mse: 0.0101\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 1s 108ms/step - loss: 0.0046 - mse: 0.0091\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 1s 102ms/step - loss: 0.0042 - mse: 0.0085\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 1s 100ms/step - loss: 0.0042 - mse: 0.0084\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 0s 48ms/step - loss: 0.0041 - mse: 0.0082\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.0037 - mse: 0.0074\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.0035 - mse: 0.0070\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.0034 - mse: 0.0068\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0032 - mse: 0.0064\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.0031 - mse: 0.0063\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.0030 - mse: 0.0060\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.0029 - mse: 0.0058\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0030 - mse: 0.0061\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.0030 - mse: 0.0060\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0031 - mse: 0.0062\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0029 - mse: 0.0058\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.0027 - mse: 0.0054\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0026 - mse: 0.0052\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0025 - mse: 0.0051\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.0025 - mse: 0.0051\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.0026 - mse: 0.0052\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0026 - mse: 0.0051\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.0027 - mse: 0.0054\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0026 - mse: 0.0052\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 0s 47ms/step - loss: 0.0024 - mse: 0.0048\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 1s 60ms/step - loss: 0.0027 - mse: 0.0053\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 0s 61ms/step - loss: 0.0024 - mse: 0.0048\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 0s 47ms/step - loss: 0.0024 - mse: 0.0048\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.0021 - mse: 0.0043\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.0021 - mse: 0.0043\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0021 - mse: 0.0041\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0020 - mse: 0.0041\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.0020 - mse: 0.0039\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.0020 - mse: 0.0040\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0022 - mse: 0.0043\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0025 - mse: 0.0050\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.0021 - mse: 0.0042\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.0021 - mse: 0.0042\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.0020 - mse: 0.0040\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0021 - mse: 0.0041\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.0022 - mse: 0.0044\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.0020 - mse: 0.0041\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.0018 - mse: 0.0036\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.0018 - mse: 0.0035\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.0019 - mse: 0.0037\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 0.0019 - mse: 0.0038\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.0020 - mse: 0.0040\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 0.0016 - mse: 0.0033\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 0.0019 - mse: 0.0039\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 0.0018 - mse: 0.0036\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 0.0019 - mse: 0.0037\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 0.0016 - mse: 0.0033\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 0.0018 - mse: 0.0036\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.0016 - mse: 0.0032\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Epoch 1/100\n",
            "8/8 [==============================] - 3s 30ms/step - loss: 0.3147 - mse: 0.6841\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.2793 - mse: 0.6003\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.2493 - mse: 0.5323\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.2224 - mse: 0.4721\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.1990 - mse: 0.4202\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.1786 - mse: 0.3753\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.1605 - mse: 0.3359\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.1444 - mse: 0.3008\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.1296 - mse: 0.2687\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.1160 - mse: 0.2390\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.1036 - mse: 0.2123\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0926 - mse: 0.1887\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0831 - mse: 0.1684\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0748 - mse: 0.1510\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.0675 - mse: 0.1358\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.0611 - mse: 0.1225\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0555 - mse: 0.1111\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0505 - mse: 0.1010\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0461 - mse: 0.0922\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0422 - mse: 0.0845\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0392 - mse: 0.0783\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0363 - mse: 0.0727\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0334 - mse: 0.0668\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 0.0311 - mse: 0.0621\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 0s 48ms/step - loss: 0.0291 - mse: 0.0581\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 0s 47ms/step - loss: 0.0273 - mse: 0.0546\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.0257 - mse: 0.0514\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 0.0243 - mse: 0.0486\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 0.0232 - mse: 0.0464\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 0.0221 - mse: 0.0441\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 1s 75ms/step - loss: 0.0210 - mse: 0.0420\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.0200 - mse: 0.0401\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 1s 82ms/step - loss: 0.0192 - mse: 0.0383\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 1s 78ms/step - loss: 0.0185 - mse: 0.0369\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 0.0177 - mse: 0.0354\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 0s 47ms/step - loss: 0.0171 - mse: 0.0342\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0166 - mse: 0.0331\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0161 - mse: 0.0321\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0156 - mse: 0.0311\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0151 - mse: 0.0303\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0146 - mse: 0.0293\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.0142 - mse: 0.0285\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0139 - mse: 0.0278\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0135 - mse: 0.0271\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0133 - mse: 0.0265\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.0136 - mse: 0.0273\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0131 - mse: 0.0263\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0127 - mse: 0.0254\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0124 - mse: 0.0249\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0121 - mse: 0.0243\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0118 - mse: 0.0236\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0115 - mse: 0.0230\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0112 - mse: 0.0224\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0110 - mse: 0.0220\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0107 - mse: 0.0214\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0105 - mse: 0.0210\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0103 - mse: 0.0206\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0102 - mse: 0.0204\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0099 - mse: 0.0197\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0095 - mse: 0.0190\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0096 - mse: 0.0192\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0091 - mse: 0.0182\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0086 - mse: 0.0172\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0084 - mse: 0.0167\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0086 - mse: 0.0172\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.0085 - mse: 0.0170\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 0.0082 - mse: 0.0165\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 0.0075 - mse: 0.0149\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 0.0071 - mse: 0.0141\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 0.0068 - mse: 0.0136\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 0.0066 - mse: 0.0132\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 0.0066 - mse: 0.0132\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 0s 49ms/step - loss: 0.0058 - mse: 0.0115\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.0055 - mse: 0.0111\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0053 - mse: 0.0106\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0050 - mse: 0.0100\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0047 - mse: 0.0095\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0046 - mse: 0.0093\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0045 - mse: 0.0089\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0042 - mse: 0.0085\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0044 - mse: 0.0089\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0048 - mse: 0.0096\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0041 - mse: 0.0082\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0037 - mse: 0.0075\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0036 - mse: 0.0072\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0035 - mse: 0.0071\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0033 - mse: 0.0066\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0040 - mse: 0.0080\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.0034 - mse: 0.0069\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0032 - mse: 0.0063\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0037 - mse: 0.0074\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0031 - mse: 0.0062\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0029 - mse: 0.0057\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0042 - mse: 0.0084\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.0037 - mse: 0.0073\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0028 - mse: 0.0056\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0030 - mse: 0.0059\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0026 - mse: 0.0053\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0025 - mse: 0.0050\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0025 - mse: 0.0050\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "5일 예측값 [[488711.44 485581.88 494942.75 522234.25 490867.88]]\n",
            "10일 예측값 [[522466.34 520864.   526649.25 547730.5  530507.25 510826.06 539706.94\n",
            "  507908.28 523129.38 527088.6 ]]\n",
            "/n\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-2ada8c5aefa5>:177: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  close_5df['Date'] = pd.to_datetime(close_5df['Date'])  # Date 열을 날짜로 변환\n",
            "<ipython-input-5-2ada8c5aefa5>:182: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  close_10df['Date'] = pd.to_datetime(close_10df['Date'])  # Date 열을 날짜로 변환\n"
          ]
        }
      ],
      "source": [
        "# 종목별로 불러와서 예측하기\n",
        "for company in companies:\n",
        "  code=merged_df[merged_df['Name']== company]['Code'].values[0]\n",
        "  stock_data = fdr.DataReader(code, start='2015-01-01', end=today)\n",
        "  stock_data.reset_index(inplace=True)\n",
        "  company_data=stock.get_market_fundamental_by_date(fromdate=\"20150101\", todate=today2, ticker=code)\n",
        "  company_data.reset_index(inplace=True)\n",
        "  company_data.rename(columns = {'날짜':'Date'}, inplace=True)\n",
        "  df=pd.merge(stock_data, company_data, on='Date', how='left')\n",
        "  df=pd.merge(df, df1, on='Date', how='left')\n",
        "  df=pd.merge(df, data, on='Date', how='left')\n",
        "  df=df.fillna(method='ffill')\n",
        "\n",
        "  csv_df = df.loc[:, ['Date', 'Close', 'BPS', 'EPS','금리', '환율']]\n",
        "  csv_df = csv_df.set_index('Date') # 날짜를 index로 바꿈\n",
        "  csv_df.dropna()\n",
        "\n",
        "  # 날짜 빼고 정규화 작업 진행 -> MinMaxScaler 사용\n",
        "  scaler = MinMaxScaler()\n",
        "\n",
        "  # 정규화 수행 -> 정규화된 데이터프레임은 scaled_df\n",
        "  scale_cols = ['Close', 'BPS', 'EPS', '금리', '환율']\n",
        "  scaled_df = scaler.fit_transform(csv_df[scale_cols]) # 정규화된 데이터는 넘파이 형태\n",
        "  scaled_df = pd.DataFrame(scaled_df, columns = scale_cols) # Pandas DataFrame 형태로 변경\n",
        "  scaled_csv_df = scaled_df.set_index(csv_df.index)\n",
        "\n",
        "  # 입력데이터 -> 이전날까지의 종가와 변수들\n",
        "  # 정답데이터 -> 다음날의 종가\n",
        "  feature_cols = ['Close', 'BPS', 'EPS', '금리', '환율']\n",
        "  label_cols = ['Close']\n",
        "\n",
        "  # 입력데이터, 정답데이터 프레임 -> feature_df, label_df\n",
        "  feature_df = scaled_csv_df[feature_cols]\n",
        "  label_df = scaled_csv_df[label_cols]\n",
        "\n",
        "  # DataFrame을 Numpy 형태로 저장\n",
        "  feature_np = feature_df.to_numpy()\n",
        "  label_np = label_df.to_numpy()\n",
        "\n",
        "  window_size = 80  # window_size 만큼의 입력데이터를 이용해 바로 다음 값에 오는 Close 값을 예측\n",
        "  X, y = make_sequence_dataset(feature_np, label_np, window_size) # X에는 np.array(feature_list), y에는 np.array(label_list) 가 대입됨\n",
        "\n",
        "  # 모델 훈련을 위한 준비 -> 훈련을 하고, 제대로 훈련이 됐는지 테스트\n",
        "  split = int(len(X)*0.7) # 테스트 데이터로 분리 -> train:test = 7:3\n",
        "\n",
        "  # 훈련data 는 전체 데이터의 70퍼센트\n",
        "  X_train = X[0:split]\n",
        "  y_train = y[0:split]\n",
        "\n",
        "  # 테스트data 는 전체 데이터의 30퍼센트\n",
        "  X_test = X[split:]\n",
        "  y_test = y[split:]\n",
        "\n",
        "  ## 5일 예측\n",
        "  #LSTM 모델 구축\n",
        "  model = Sequential()\n",
        "\n",
        "  # 1차원 feature map 생성\n",
        "  model.add(Conv1D(filters=32, kernel_size=5,\n",
        "            padding=\"causal\",\n",
        "            activation=\"relu\",\n",
        "            input_shape=[window_size, 5]))# input_shape = (40,5) -> 다음값 예측을 위한 이전 40개(window_size)의 값과 5개의 특성을 입력으로 넣습니다\n",
        "\n",
        "  # LSTM layer\n",
        "  model.add(LSTM(units = 16, activation = 'tanh'))\n",
        "  model.add(Dense(units = 16, activation = 'sigmoid'))\n",
        "  model.add(Dense(units = 5)) # 출력층\n",
        "\n",
        "  # 모델 컴파일\n",
        "  loss = Huber()\n",
        "  optimizer = Adam(0.0005)\n",
        "  model.compile(loss=loss, optimizer=optimizer, metrics=['mse']) # 손실 함수는 Huber, 옵티마이저는 Adam,  평가지표는 mse로 설정\n",
        "\n",
        "  # 조기종료 설정 -> earlystopping은 10번의 epoch통안 loss 개선이 없다면 학습을 멈춤\n",
        "  earlystopping = EarlyStopping(monitor='loss', patience=10)\n",
        "\n",
        "\n",
        "  # 모델 학습 -> epoch은 100번 진행\n",
        "  model.fit(X_train, y_train, epochs=100, batch_size=32, callbacks=[earlystopping])\n",
        "\n",
        "  # 주가 예측 -> test 데이터를 이용하여 학습된 LSTM모델을 테스트\n",
        "  predictions = model.predict(X_test)\n",
        "\n",
        "  # 실제값 변환\n",
        "  # 실제값으로 변화시키기 위해서 기존 데이터에서 종가의 최댓값과 최솟값을 가져옵니다\n",
        "  close_min = csv_df['Close'].min()\n",
        "  close_max = csv_df['Close'].max()\n",
        "\n",
        "  # MinMaxScaler이용해서 실제값으로 역변환\n",
        "  scaler2 = MinMaxScaler()\n",
        "  scaled_df2 = scaler2.fit_transform(csv_df[['Close']])\n",
        "\n",
        "  # MinMaxScaler에 정규화에 사용한 최솟값과 최댓값을 설정\n",
        "  scaler2.data_min_ = close_min  # 정규화에 사용한 최솟값\n",
        "  scaler2.data_max_ = close_max  # 정규화에 사용한 최댓값\n",
        "\n",
        "  # 예측한 출력값을 실제값으로 역변환\n",
        "  original_pred_values = scaler2.inverse_transform(predictions)\n",
        "\n",
        "  # 실제로 에측하기\n",
        "  # feature_df 에서 가장 최근의 값을 window_size 만큼 가져옴\n",
        "  pred_feature = feature_df.tail(window_size)\n",
        "\n",
        "  pred_feature_list = []\n",
        "  pred_feature_list.append(pred_feature)\n",
        "  pred_feature = np.array(pred_feature_list)\n",
        "\n",
        "  # 5일 예측 -> 5일까지의 예측값 5개 출력\n",
        "  predictions_5d = model.predict(pred_feature)\n",
        "  pred_values_5d = scaler2.inverse_transform(predictions_5d)\n",
        "\n",
        "\n",
        "  ##10일 예측\n",
        "  #LSTM 모델 구축\n",
        "  model = Sequential()\n",
        "\n",
        "  # 1차원 feature map 생성\n",
        "  model.add(Conv1D(filters=32, kernel_size=5,\n",
        "            padding=\"causal\",\n",
        "            activation=\"relu\",\n",
        "            input_shape=[window_size, 5]))# input_shape = (40,5) -> 다음값 예측을 위한 이전 40개(window_size)의 값과 5개의 특성을 입력으로 넣습니다\n",
        "\n",
        "  # LSTM layer\n",
        "  model.add(LSTM(units = 16, activation = 'tanh'))\n",
        "  model.add(Dense(units = 16, activation = 'sigmoid'))\n",
        "  model.add(Dense(units = 10)) # 출력층\n",
        "\n",
        "    # 모델 컴파일\n",
        "  loss = Huber()\n",
        "  optimizer = Adam(0.0005)\n",
        "  model.compile(loss=loss, optimizer=optimizer, metrics=['mse']) # 손실 함수는 Huber, 옵티마이저는 Adam,  평가지표는 mse로 설정\n",
        "\n",
        "  # 조기종료 설정 -> earlystopping은 10번의 epoch통안 loss 개선이 없다면 학습을 멈춤\n",
        "  earlystopping = EarlyStopping(monitor='loss', patience=10)\n",
        "\n",
        "\n",
        "  # 모델 학습 -> epoch은 100번 진행\n",
        "  model.fit(X_train, y_train, epochs=100, batch_size=32, callbacks=[earlystopping])\n",
        "\n",
        "  # 주가 예측 -> test 데이터를 이용하여 학습된 LSTM모델을 테스트\n",
        "  predictions = model.predict(X_test)\n",
        "\n",
        "  # 실제값 변환\n",
        "  # 실제값으로 변화시키기 위해서 기존 데이터에서 종가의 최댓값과 최솟값을 가져옵니다\n",
        "  close_min = csv_df['Close'].min()\n",
        "  close_max = csv_df['Close'].max()\n",
        "\n",
        "  # MinMaxScaler이용해서 실제값으로 역변환\n",
        "  scaler2 = MinMaxScaler()\n",
        "  scaled_df2 = scaler2.fit_transform(csv_df[['Close']])\n",
        "\n",
        "  # MinMaxScaler에 정규화에 사용한 최솟값과 최댓값을 설정\n",
        "  scaler2.data_min_ = close_min  # 정규화에 사용한 최솟값\n",
        "  scaler2.data_max_ = close_max  # 정규화에 사용한 최댓값\n",
        "\n",
        "  # 예측한 출력값을 실제값으로 역변환\n",
        "  original_pred_values = scaler2.inverse_transform(predictions)\n",
        "\n",
        "  # 실제로 에측하기\n",
        "  # feature_df 에서 가장 최근의 값을 window_size 만큼 가져옴\n",
        "  pred_feature = feature_df.tail(window_size)\n",
        "\n",
        "  pred_feature_list = []\n",
        "  pred_feature_list.append(pred_feature)\n",
        "  pred_feature = np.array(pred_feature_list)\n",
        "\n",
        "  # 10일 예측 -> 10일까지의 예측값 10개 출력\n",
        "  predictions_10d = model.predict(pred_feature)\n",
        "  pred_values_10d = scaler2.inverse_transform(predictions_10d)\n",
        "\n",
        "  #pred_values_5d = pred_values_5d.flatten().tolist()\n",
        "  #pred_values_10d = pred_values_10d.flatten().tolist()\n",
        "\n",
        "  close_5df = csv_df[['Close']] # 종가데이터\n",
        "  close_5df.reset_index(inplace=True)\n",
        "  close_5df.columns = ['Date', 'Close']  # 열 이름 변경\n",
        "  close_5df['Date'] = pd.to_datetime(close_5df['Date'])  # Date 열을 날짜로 변환\n",
        "\n",
        "  close_10df = csv_df[['Close']] # 종가데이터\n",
        "  close_10df.reset_index(inplace=True)\n",
        "  close_10df.columns = ['Date', 'Close']  # 열 이름 변경\n",
        "  close_10df['Date'] = pd.to_datetime(close_10df['Date'])  # Date 열을 날짜로 변환\n",
        "\n",
        "  pred5dCsvDf = pd.DataFrame(columns = ['Date', 'Close'])\n",
        "  pred10dCsvDf = pd.DataFrame(columns = ['Date', 'Close'])\n",
        "\n",
        "  # 5일 예측 날짜와 종가\n",
        "  for i in range (len(pred_values_5d[0])):\n",
        "    # 마지막 날짜를 찾고 그 다음 날짜 계산\n",
        "    last_date = close_5df['Date'].max()\n",
        "    next_date = last_date + pd.DateOffset(days=1)  # 하루를 더해 다음 날짜 계산\n",
        "    # 새로운 데이터 생성 및 추가\n",
        "    new_data = {'Date': [next_date], 'Close': [pred_values_5d[0,i]]}\n",
        "    new_df = pd.DataFrame(new_data)\n",
        "    pred5dCsvDf = pd.concat([pred5dCsvDf, new_df], ignore_index=True)\n",
        "    # 그 다음 날짜 계산을 위한 마지막 날짜 변경\n",
        "    close_5df = pd.concat([close_5df, new_df], ignore_index=True)\n",
        "\n",
        "  # 10일 예측 날짜와 종가\n",
        "  for i in range (len(pred_values_10d[0])):\n",
        "    # 마지막 날짜를 찾고 그 다음 날짜 계산\n",
        "    last_date = close_10df['Date'].max()\n",
        "    next_date = last_date + pd.DateOffset(days=1)  # 하루를 더해 다음 날짜 계산\n",
        "    # 새로운 데이터 생성 및 추가\n",
        "    new_data = {'Date': [next_date], 'Close': [pred_values_10d[0,i]]}\n",
        "    new_df = pd.DataFrame(new_data)\n",
        "    pred10dCsvDf = pd.concat([pred10dCsvDf, new_df], ignore_index=True)\n",
        "    # 그 다음 날짜 계산을 위한 마지막 날짜 변경\n",
        "    close_10df = pd.concat([close_10df, new_df], ignore_index=True)\n",
        "\n",
        "  # Date 열을 문자열로 다시 변환 (예: 'YYYY-MM-DD' 형식)\n",
        "  pred5dCsvDf['Date'] = pred5dCsvDf['Date'].dt.strftime('%Y-%m-%d')\n",
        "  pred10dCsvDf['Date'] = pred10dCsvDf['Date'].dt.strftime('%Y-%m-%d')\n",
        "\n",
        "  day_five[company] = pred5dCsvDf.values.tolist()\n",
        "  day_ten[company] = pred10dCsvDf.values.tolist()\n",
        "\n",
        "  print(company,code)\n",
        "  print('5일 예측값', pred_values_5d)\n",
        "  print('10일 예측값', pred_values_10d)\n",
        "  print('/n')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "qDmpu8aRxVLD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "day_five"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIPJHm-Y0TjI",
        "outputId": "ea8e8a7b-709f-4e86-8182-41d47e61e75e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'삼성전자': [['2023-09-22', 63507.37890625],\n",
              "  ['2023-09-23', 62880.8515625],\n",
              "  ['2023-09-24', 61536.74609375],\n",
              "  ['2023-09-25', 62177.9375],\n",
              "  ['2023-09-26', 63237.64453125]],\n",
              " 'LG에너지솔루션': [['2023-09-22', 488711.4375],\n",
              "  ['2023-09-23', 485581.875],\n",
              "  ['2023-09-24', 494942.75],\n",
              "  ['2023-09-25', 522234.25],\n",
              "  ['2023-09-26', 490867.875]]}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "day_ten"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ue85wW5H0W47",
        "outputId": "3583efe7-a873-41c3-fa85-38da030088e2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'삼성전자': [['2023-09-22', 64283.6796875],\n",
              "  ['2023-09-23', 62747.515625],\n",
              "  ['2023-09-24', 65553.3203125],\n",
              "  ['2023-09-25', 65396.3984375],\n",
              "  ['2023-09-26', 67215.4765625],\n",
              "  ['2023-09-27', 66289.40625],\n",
              "  ['2023-09-28', 62844.28515625],\n",
              "  ['2023-09-29', 67169.6953125],\n",
              "  ['2023-09-30', 65918.0703125],\n",
              "  ['2023-10-01', 64909.5390625]],\n",
              " 'LG에너지솔루션': [['2023-09-22', 522466.34375],\n",
              "  ['2023-09-23', 520864.0],\n",
              "  ['2023-09-24', 526649.25],\n",
              "  ['2023-09-25', 547730.5],\n",
              "  ['2023-09-26', 530507.25],\n",
              "  ['2023-09-27', 510826.0625],\n",
              "  ['2023-09-28', 539706.9375],\n",
              "  ['2023-09-29', 507908.28125],\n",
              "  ['2023-09-30', 523129.375],\n",
              "  ['2023-10-01', 527088.625]]}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "    'day_five': day_five\n",
        "}\n",
        "\n",
        "server_url = 'https://eb86-39-118-146-59.ngrok-free.app/day_five'\n",
        "\n",
        "response = requests.post(server_url, json=data)  # POST 요청으로 변경, 헤더는 자동으로 설정됨\n",
        "\n",
        "if response.status_code == 200:\n",
        "    print('성공')\n",
        "else:\n",
        "    print('실패:', response.status_code)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CAeQrnUk0awu",
        "outputId": "f0f614b7-87ad-46f9-f7ea-571c2c8e7dd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "성공\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "    'day_ten': day_ten\n",
        "}\n",
        "\n",
        "server_url = 'https://eb86-39-118-146-59.ngrok-free.app/day_ten'\n",
        "\n",
        "response = requests.post(server_url, json=data)  # POST 요청으로 변경, 헤더는 자동으로 설정됨\n",
        "\n",
        "if response.status_code == 200:\n",
        "    print('성공')\n",
        "else:\n",
        "    print('실패:', response.status_code)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWREdHPIG2BL",
        "outputId": "90bb204d-a1f0-4840-9d7c-c7108959cc8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "성공\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}